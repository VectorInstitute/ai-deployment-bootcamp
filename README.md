# Deployment of AI Models Bootcamp

This repository houses the reference implementations for the Deployment of AI Models
Bootcamp.

## About

The Deployment of AI Models Bootcamp aims to introduce and explain the details of the
different elements and concepts of a production AI model inferencing pipeline.

This repository contains reference implementations with terraform and python scripts
to make online (real-time) and offline (batch) pipelines in cloud providers, as well
as detailed instructions on how to upload models, configure and run the code,
and testing the pipelines.

## Repository Structure

- **reference_implementations/**: Reference Implementations are organized by cloud
provider. Each reference implementation has its own directory containing scripts,
terraform plans, and a README for guidance.
- **data/**: Includes sample datasets or links to datasets used in the bootcamp,
along with usage instructions. It also contains the implementation of dataset modules,
and anything related to that.


### Reference Implementations Directory

Each cloud provider covered in the bootcamp has a dedicated directory in the
`reference_implementations/` directory. In each directory, there is a README file
that provides an overview of the code, prerequisites, and detailed instructions.

Here is the list of the covered cloud providers:
- [Google Cloud Provider (GCP)](reference_implementations/gcp)
- [Amazon Web Services (AWS)](reference_implementations/aws)

## Getting Started

To get started with this bootcamp:
1. Clone this repository to your machine.
2. Navigate to the directory of the cloud provider you are going to use
3. Follow the instructions in the README file.

## License
This project is licensed under the terms of the [LICENSE.md](LICENSE.md) file located
in the root directory of this repository.

## Contribution
To get started with contributing to our project, please read our
[CONTRIBUTING.md](CONTRIBUTING.md) guide. 

## Contact Information

For more information or help with navigating this repository, please contact
Marcelo Lotif at [marcelo.lotif@vectorinstitute.ai](marcelo.lotif@vectorinstitute.ai).
